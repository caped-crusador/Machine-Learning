{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution Neural network with three Convolution layers \n",
    "performed on MNIST data and the results are being stored in _results_conv3.txt_ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Shakti\\AppData\\Local\\Temp\\tmp4g1piyhq\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Shakti\\\\AppData\\\\Local\\\\Temp\\\\tmp4g1piyhq', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000014253F6A7B8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "shape after pool3 :  (10, 7, 7, 64)\n",
      "loss: Tensor(\"sparse_softmax_cross_entropy_loss/value:0\", shape=(), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Shakti\\AppData\\Local\\Temp\\tmp4g1piyhq\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.2868817, step = 1\n",
      "INFO:tensorflow:global_step/sec: 15.2649\n",
      "INFO:tensorflow:loss = 2.2806568, step = 101 (6.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1305\n",
      "INFO:tensorflow:loss = 2.2819777, step = 201 (6.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6957\n",
      "INFO:tensorflow:loss = 2.2633474, step = 301 (6.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.418\n",
      "INFO:tensorflow:loss = 2.303725, step = 401 (6.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.39\n",
      "INFO:tensorflow:loss = 2.267308, step = 501 (6.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7504\n",
      "INFO:tensorflow:loss = 2.2412572, step = 601 (6.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8599\n",
      "INFO:tensorflow:loss = 2.2091184, step = 701 (6.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0187\n",
      "INFO:tensorflow:loss = 2.2190814, step = 801 (7.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5099\n",
      "INFO:tensorflow:loss = 2.1976502, step = 901 (7.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.346\n",
      "INFO:tensorflow:loss = 2.068393, step = 1001 (6.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8062\n",
      "INFO:tensorflow:loss = 2.1303456, step = 1101 (7.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0539\n",
      "INFO:tensorflow:loss = 2.0813522, step = 1201 (6.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.952\n",
      "INFO:tensorflow:loss = 1.9555902, step = 1301 (6.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1951\n",
      "INFO:tensorflow:loss = 1.6625614, step = 1401 (6.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7856\n",
      "INFO:tensorflow:loss = 1.5507376, step = 1501 (6.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9859\n",
      "INFO:tensorflow:loss = 1.6684052, step = 1601 (7.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3751\n",
      "INFO:tensorflow:loss = 1.331423, step = 1701 (8.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6404\n",
      "INFO:tensorflow:loss = 1.392603, step = 1801 (8.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.018\n",
      "INFO:tensorflow:loss = 0.8590194, step = 1901 (7.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0609\n",
      "INFO:tensorflow:loss = 0.62355155, step = 2001 (6.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7683\n",
      "INFO:tensorflow:loss = 0.9380116, step = 2101 (6.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2011\n",
      "INFO:tensorflow:loss = 1.0173861, step = 2201 (7.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0985\n",
      "INFO:tensorflow:loss = 0.884963, step = 2301 (8.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.005\n",
      "INFO:tensorflow:loss = 0.56896824, step = 2401 (7.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4228\n",
      "INFO:tensorflow:loss = 0.98168516, step = 2501 (7.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4163\n",
      "INFO:tensorflow:loss = 0.8369156, step = 2601 (7.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5135\n",
      "INFO:tensorflow:loss = 0.46208563, step = 2701 (6.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1504\n",
      "INFO:tensorflow:loss = 0.2953636, step = 2801 (6.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3481\n",
      "INFO:tensorflow:loss = 0.6829553, step = 2901 (6.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1518\n",
      "INFO:tensorflow:loss = 0.49412605, step = 3001 (6.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1085\n",
      "INFO:tensorflow:loss = 0.9266905, step = 3101 (6.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9422\n",
      "INFO:tensorflow:loss = 0.1506813, step = 3201 (6.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2926\n",
      "INFO:tensorflow:loss = 0.15795164, step = 3301 (6.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1976\n",
      "INFO:tensorflow:loss = 0.47178298, step = 3401 (6.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1194\n",
      "INFO:tensorflow:loss = 0.513955, step = 3501 (7.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6766\n",
      "INFO:tensorflow:loss = 0.38571048, step = 3601 (6.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1752\n",
      "INFO:tensorflow:loss = 0.12890223, step = 3701 (6.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.4033\n",
      "INFO:tensorflow:loss = 0.27616057, step = 3801 (6.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2519\n",
      "INFO:tensorflow:loss = 0.05831728, step = 3901 (6.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0256\n",
      "INFO:tensorflow:loss = 0.3013978, step = 4001 (6.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3352\n",
      "INFO:tensorflow:loss = 0.2872343, step = 4101 (6.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9627\n",
      "INFO:tensorflow:loss = 0.69701064, step = 4201 (6.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.278\n",
      "INFO:tensorflow:loss = 0.2925049, step = 4301 (6.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7318\n",
      "INFO:tensorflow:loss = 0.29573506, step = 4401 (7.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7057\n",
      "INFO:tensorflow:loss = 0.5841325, step = 4501 (6.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2685\n",
      "INFO:tensorflow:loss = 0.18677866, step = 4601 (6.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2852\n",
      "INFO:tensorflow:loss = 0.060026355, step = 4701 (6.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.4498\n",
      "INFO:tensorflow:loss = 0.39541003, step = 4801 (6.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3843\n",
      "INFO:tensorflow:loss = 0.2757421, step = 4901 (6.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8512\n",
      "INFO:tensorflow:loss = 0.363951, step = 5001 (6.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8465\n",
      "INFO:tensorflow:loss = 0.48966938, step = 5101 (7.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4847\n",
      "INFO:tensorflow:loss = 0.20819049, step = 5201 (6.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6011\n",
      "INFO:tensorflow:loss = 0.3969488, step = 5301 (6.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2994\n",
      "INFO:tensorflow:loss = 0.64471406, step = 5401 (6.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2418\n",
      "INFO:tensorflow:loss = 0.15839437, step = 5501 (6.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3675\n",
      "INFO:tensorflow:loss = 0.36656672, step = 5601 (6.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.384\n",
      "INFO:tensorflow:loss = 0.67482543, step = 5701 (6.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.4141\n",
      "INFO:tensorflow:loss = 0.380824, step = 5801 (6.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.304\n",
      "INFO:tensorflow:loss = 0.33492512, step = 5901 (6.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2891\n",
      "INFO:tensorflow:loss = 0.15773538, step = 6001 (6.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5126\n",
      "INFO:tensorflow:loss = 0.38879928, step = 6101 (6.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1177\n",
      "INFO:tensorflow:loss = 0.06196193, step = 6201 (7.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3222\n",
      "INFO:tensorflow:loss = 0.34168407, step = 6301 (6.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.4211\n",
      "INFO:tensorflow:loss = 0.21899246, step = 6401 (6.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3681\n",
      "INFO:tensorflow:loss = 0.08312904, step = 6501 (6.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.4857\n",
      "INFO:tensorflow:loss = 0.34152463, step = 6601 (6.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2042\n",
      "INFO:tensorflow:loss = 0.78524673, step = 6701 (6.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3558\n",
      "INFO:tensorflow:loss = 0.14410645, step = 6801 (6.512 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 15.2659\n",
      "INFO:tensorflow:loss = 0.5116021, step = 6901 (6.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3496\n",
      "INFO:tensorflow:loss = 0.3034646, step = 7001 (6.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8058\n",
      "INFO:tensorflow:loss = 0.13582945, step = 7101 (7.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3202\n",
      "INFO:tensorflow:loss = 0.17263336, step = 7201 (6.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1299\n",
      "INFO:tensorflow:loss = 0.16730571, step = 7301 (6.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3854\n",
      "INFO:tensorflow:loss = 0.060874444, step = 7401 (6.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2729\n",
      "INFO:tensorflow:loss = 0.30054948, step = 7501 (6.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1818\n",
      "INFO:tensorflow:loss = 0.28127676, step = 7601 (6.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.285\n",
      "INFO:tensorflow:loss = 0.06084297, step = 7701 (6.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.4135\n",
      "INFO:tensorflow:loss = 0.8076941, step = 7801 (6.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1797\n",
      "INFO:tensorflow:loss = 0.4333534, step = 7901 (6.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5923\n",
      "INFO:tensorflow:loss = 0.24505384, step = 8001 (7.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9131\n",
      "INFO:tensorflow:loss = 0.12654817, step = 8101 (7.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0467\n",
      "INFO:tensorflow:loss = 0.04232907, step = 8201 (6.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1751\n",
      "INFO:tensorflow:loss = 0.34168723, step = 8301 (6.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1336\n",
      "INFO:tensorflow:loss = 0.22614232, step = 8401 (7.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8613\n",
      "INFO:tensorflow:loss = 0.1249029, step = 8501 (6.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0812\n",
      "INFO:tensorflow:loss = 0.24088386, step = 8601 (6.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.5185\n",
      "INFO:tensorflow:loss = 0.12612157, step = 8701 (6.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9552\n",
      "INFO:tensorflow:loss = 0.121934235, step = 8801 (6.702 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8810 into C:\\Users\\Shakti\\AppData\\Local\\Temp\\tmp4g1piyhq\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 13.7407\n",
      "INFO:tensorflow:loss = 0.36818686, step = 8901 (7.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6141\n",
      "INFO:tensorflow:loss = 0.13421766, step = 9001 (6.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6762\n",
      "INFO:tensorflow:loss = 0.08731184, step = 9101 (6.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.4279\n",
      "INFO:tensorflow:loss = 0.17318337, step = 9201 (6.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1196\n",
      "INFO:tensorflow:loss = 0.28478074, step = 9301 (6.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3072\n",
      "INFO:tensorflow:loss = 0.20455824, step = 9401 (6.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8434\n",
      "INFO:tensorflow:loss = 0.19335783, step = 9501 (6.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2047\n",
      "INFO:tensorflow:loss = 0.1897016, step = 9601 (6.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8846\n",
      "INFO:tensorflow:loss = 0.11209848, step = 9701 (6.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2884\n",
      "INFO:tensorflow:loss = 0.17584208, step = 9801 (6.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7757\n",
      "INFO:tensorflow:loss = 0.056669105, step = 9901 (6.339 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into C:\\Users\\Shakti\\AppData\\Local\\Temp\\tmp4g1piyhq\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.18168409.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "shape after pool3 :  (?, 7, 7, 64)\n",
      "loss: Tensor(\"sparse_softmax_cross_entropy_loss/value:0\", shape=(), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-21-16:14:20\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Shakti\\AppData\\Local\\Temp\\tmp4g1piyhq\\model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-21-16:14:36\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.9482, global_step = 10000, loss = 0.17655016\n",
      "{'accuracy': 0.9482, 'loss': 0.17655016, 'global_step': 10000}\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "# tf.logging.set_verbosity(tf.logging.INFO)\n",
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "num_classes = len(classes)\n",
    "\n",
    "\n",
    "def my_cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "    # MNIST images are 28x28 pixels, and have one color channel\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "    # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    # First max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2\n",
    "    # Computes 64 features using a 5x5 filter.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #2\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    #third convolution layer\n",
    "    conv3 = tf.layers.conv2d(\n",
    "        inputs=pool2,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    print(\"shape after pool3 : \", conv3.shape)\n",
    "\n",
    "    # pooling third layer\n",
    "\n",
    "    # Flatten tensor into a batch of vectors\n",
    "    # Input Tensor Shape: [batch_size, 7, 7, 64]    \n",
    "    # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "    pool3_flat = tf.reshape(conv3, [-1, 7 * 7 * 64])\n",
    "\n",
    "    # Dense Layer\n",
    "    # Densely connected layer with 1024 neurons\n",
    "    # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "    # Output Tensor Shape: [batch_size, 1024]\n",
    "    dense = tf.layers.dense(inputs=pool3_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "    # Add dropout operation; 0.6 probability that element will be kept\n",
    "    dropout = tf.layers.dropout(\n",
    "        inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits layer\n",
    "    # Input Tensor Shape: [batch_size, 1024]\n",
    "    # Output Tensor Shape: [batch_size, 10]\n",
    "    logits = tf.layers.dense(inputs=dropout, units=num_classes)\n",
    "\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    print(\"loss:\", loss)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    #  Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "#  # Load training and eval data\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "\n",
    "train_data = mnist.train.images  # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "indices = np.isin(train_labels, classes)\n",
    "sample_train_data = train_data[indices, :]\n",
    "sample_train_labels = train_labels[indices]\n",
    "\n",
    "eval_data = mnist.test.images  # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "indices_test = np.isin(eval_labels, classes)\n",
    "sample_eval_data = eval_data[indices_test, :]\n",
    "sample_eval_labels = eval_labels[indices_test]\n",
    "\n",
    "# Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=my_cnn_model_fn)  # , model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": sample_train_data},\n",
    "    y=sample_train_labels,\n",
    "    batch_size=10,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "mnist_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=10000)\n",
    "\n",
    "# Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": sample_eval_data},\n",
    "    y=sample_eval_labels,\n",
    "    batch_size=10,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)\n",
    "\n",
    "\n",
    "text_file = open(\"results_conv3.txt\", \"w\")\n",
    "text_file.write(str(eval_results))\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that the accuracy of the Convolutional neural network with 3 convolution layers is --%, which is "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
